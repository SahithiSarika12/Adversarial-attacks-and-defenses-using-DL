{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/as791/Adversarial-Example-Attack-and-Defense/blob/master/Adversarial_Example_(Attack_and_defense).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGrkQarm97Ye"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0Rt-4inOweid",
    "outputId": "8b301031-02dd-4473-b45a-71b2564b9915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2390da3f870>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkxWvr7aviFj"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,), (1.0,))])\n",
    "dataset = datasets.MNIST(root = './data', train=True, transform = transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "test_set = datasets.MNIST(root = './data', train=False, transform = transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=1,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XVMI7iDTmarW",
    "outputId": "6b3ed0fd-2eda-4615-a6a0-1f8ebf031496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 50000 Validation data: 10000 Test data:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\",len(train_loader),\"Validation data:\",len(val_loader),\"Test data: \",len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pknHQZaMYpwC"
   },
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojfonaxgSvQE"
   },
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-WKoIKbEYk1"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "    self.dropout1 = nn.Dropout2d(0.25)\n",
    "    self.dropout2 = nn.Dropout2d(0.5)\n",
    "    self.fc1 = nn.Linear(9216, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc2(x)\n",
    "    output = F.log_softmax(x, dim=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUN6hEiBErhm"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AptkqWI9YljT"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
    "criterion = nn.NLLLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiX8fKnhYMu4"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-674b124d6103>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-674b124d6103>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    return train_loss,val_loss_per_epoch`\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def fit(model,device,train_loader,val_loader,epochs):\n",
    "  data_loader = {'train':train_loader,'val':val_loader}\n",
    "  print(\"Fitting the model...\")\n",
    "  train_loss,val_loss=[],[]\n",
    "  for epoch in range(epochs):\n",
    "    loss_per_epoch,val_loss_per_epoch=0,0\n",
    "    for phase in ('train','val'):\n",
    "      for i,data in enumerate(data_loader[phase]):\n",
    "        input,label  = data[0].to(device),data[1].to(device)\n",
    "        output = model(input)\n",
    "        #calculating loss on the output\n",
    "        loss = criterion(output,label)\n",
    "        if phase == 'train':\n",
    "          optimizer.zero_grad()\n",
    "          #grad calc w.r.t Loss func\n",
    "          loss.backward()\n",
    "          #update weights\n",
    "          optimizer.step()\n",
    "          loss_per_epoch+=loss.item()\n",
    "        else:\n",
    "          val_loss_per_epoch+=loss.item()\n",
    "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
    "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
    "    train_loss.append(loss_per_epoch/len(train_loader))\n",
    "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
    "  return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KZsY1KfZjELB",
    "outputId": "79bfe15d-c7d5-45ff-f2aa-129eed6535dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model...\n",
      "Epoch: 1 Loss: 0.27343267196599996 Val_Loss: 0.1278707585119712\n",
      "Epoch: 2 Loss: 0.10334996976574151 Val_Loss: 0.11294005433019365\n",
      "Epoch: 3 Loss: 0.08266430827667162 Val_Loss: 0.09148719198828577\n",
      "Epoch: 4 Loss: 0.07079667681123075 Val_Loss: 0.08534162389735324\n",
      "Epoch: 5 Loss: 0.06614728131990151 Val_Loss: 0.0943384021609726\n",
      "Epoch: 6 Loss: 0.060938587732866006 Val_Loss: 0.0971282098764358\n",
      "Epoch: 7 Loss: 0.059932570129024317 Val_Loss: 0.09002776223849093\n",
      "Epoch: 8 Loss: 0.058589712071406785 Val_Loss: 0.09442808880790829\n",
      "Epoch: 9 Loss: 0.043677607332639964 Val_Loss: 0.06727464544983122\n",
      "Epoch: 10 Loss: 0.04274922956048421 Val_Loss: 0.07413757487095915\n"
     ]
    }
   ],
   "source": [
    "loss,val_loss=fit(model,device,train_loader,val_loader,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "jIn4g_o7NnXH",
    "outputId": "ffe81618-de62-49ca-adab-d637e99a9693"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-64e73313de7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"*-\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"o-\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Val Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num of epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(np.arange(1,11), loss, \"*-\",label=\"Loss\")\n",
    "plt.plot(np.arange(1,11), val_loss,\"o-\",label=\"Val Loss\")\n",
    "plt.xlabel(\"Num of epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HC02Gxez9-21"
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(input,epsilon,data_grad):\n",
    "  pert_out = input + epsilon*data_grad.sign()\n",
    "  pert_out = torch.clamp(pert_out, 0, 1)\n",
    "  return pert_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUaZ34u7OtZR"
   },
   "outputs": [],
   "source": [
    "def test(model,device,test_loader,epsilon,attack):\n",
    "  correct = 0\n",
    "  adv_examples = []\n",
    "  for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      data.requires_grad = True\n",
    "      output = model(data)\n",
    "      init_pred = output.max(1, keepdim=True)[1] \n",
    "      if init_pred.item() != target.item():\n",
    "          continue\n",
    "      loss = F.nll_loss(output, target)\n",
    "      model.zero_grad()\n",
    "      loss.backward()\n",
    "      data_grad = data.grad.data\n",
    "\n",
    "      if attack == \"fgsm\":\n",
    "        perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
    "        \n",
    "      output = model(perturbed_data)\n",
    "      final_pred = output.max(1, keepdim=True)[1]\n",
    "      if final_pred.item() == target.item():\n",
    "          correct += 1\n",
    "          if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "              adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "      else:\n",
    "          if len(adv_examples) < 5:\n",
    "              adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "              adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "  final_acc = correct/float(len(test_loader))\n",
    "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "  return final_acc, adv_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GGE1r1Ui9Xu8",
    "outputId": "33eb7a4e-bc9b-4815-b7f3-6b240d251df9"
   },
   "outputs": [],
   "source": [
    "epsilons = [0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3]\n",
    "for attack in (\"fgsm\"):\n",
    "  accuracies = []\n",
    "  examples = []\n",
    "  for eps in epsilons:\n",
    "      acc, ex = test(model, device,test_loader,eps,attack)\n",
    "      accuracies.append(acc)\n",
    "      examples.append(ex)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  plt.plot(epsilons, accuracies, \"*-\")\n",
    "  plt.title(attack)\n",
    "  plt.xlabel(\"Epsilon\")\n",
    "  plt.ylabel(\"Accuracy\")\n",
    "  plt.show()\n",
    "\n",
    "  cnt = 0\n",
    "  plt.figure(figsize=(8,10))\n",
    "  for i in range(len(epsilons)):\n",
    "      for j in range(len(examples[i])):\n",
    "          cnt += 1\n",
    "          plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "          plt.xticks([], [])\n",
    "          plt.yticks([], [])\n",
    "          if j == 0:\n",
    "              plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "          orig,adv,ex = examples[i][j]\n",
    "          plt.title(\"{} -> {}\".format(orig, adv))\n",
    "          plt.imshow(ex, cmap=\"gray\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2w6XaDtSqPg"
   },
   "source": [
    "# Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsdYLXi8Zh8T"
   },
   "outputs": [],
   "source": [
    "class NetF(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NetF, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "    self.dropout1 = nn.Dropout2d(0.25)\n",
    "    self.dropout2 = nn.Dropout2d(0.5)\n",
    "    self.fc1 = nn.Linear(9216, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "class NetF1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NetF1, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "    self.dropout1 = nn.Dropout2d(0.25)\n",
    "    self.dropout2 = nn.Dropout2d(0.5)\n",
    "    self.fc1 = nn.Linear(4608, 64)\n",
    "    self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRQ2JD510gKY"
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(input,epsilon,data_grad):\n",
    "  pert_out = input + epsilon*data_grad.sign()\n",
    "  pert_out = torch.clamp(pert_out, 0, 1)\n",
    "  return pert_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozWhbnZykM-Y"
   },
   "outputs": [],
   "source": [
    "def fit(model,device,optimizer,scheduler,criterion,train_loader,val_loader,Temp,epochs):\n",
    "  data_loader = {'train':train_loader,'val':val_loader}\n",
    "  print(\"Fitting the model...\")\n",
    "  train_loss,val_loss=[],[]\n",
    "  for epoch in range(epochs):\n",
    "    loss_per_epoch,val_loss_per_epoch=0,0\n",
    "    for phase in ('train','val'):\n",
    "      for i,data in enumerate(data_loader[phase]):\n",
    "        input,label  = data[0].to(device),data[1].to(device)\n",
    "        output = model(input)\n",
    "        output = F.log_softmax(output/Temp,dim=1)\n",
    "        #calculating loss on the output\n",
    "        loss = criterion(output,label)\n",
    "        if phase == 'train':\n",
    "          optimizer.zero_grad()\n",
    "          #grad calc w.r.t Loss func\n",
    "          loss.backward()\n",
    "          #update weights\n",
    "          optimizer.step()\n",
    "          loss_per_epoch+=loss.item()\n",
    "        else:\n",
    "          val_loss_per_epoch+=loss.item()\n",
    "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
    "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
    "    train_loss.append(loss_per_epoch/len(train_loader))\n",
    "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
    "  return train_loss,val_loss\n",
    "\n",
    "def test(model,device,test_loader,epsilon,Temp,attack):\n",
    "  correct=0\n",
    "  adv_examples = []\n",
    "  for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    data.requires_grad = True\n",
    "    output = model(data)\n",
    "    output = F.log_softmax(output/Temp,dim=1)\n",
    "    init_pred = output.max(1, keepdim=True)[1] \n",
    "    if init_pred.item() != target.item():\n",
    "        continue\n",
    "    loss = F.nll_loss(output, target)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = data.grad.data\n",
    "\n",
    "    if attack == \"fgsm\":\n",
    "      perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
    "      \n",
    "    output = model(perturbed_data)\n",
    "    final_pred = output.max(1, keepdim=True)[1]\n",
    "    if final_pred.item() == target.item():\n",
    "        correct += 1\n",
    "        if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "    else:\n",
    "        if len(adv_examples) < 5:\n",
    "            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "  final_acc = correct/float(len(test_loader))\n",
    "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "  return final_acc,adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwbI3joPzmyi"
   },
   "outputs": [],
   "source": [
    "def defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons):\n",
    "\n",
    "  modelF = NetF().to(device)\n",
    "  optimizerF = optim.Adam(modelF.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
    "  schedulerF = optim.lr_scheduler.ReduceLROnPlateau(optimizerF, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "  modelF1 = NetF1().to(device)\n",
    "  optimizerF1 = optim.Adam(modelF1.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
    "  schedulerF1 = optim.lr_scheduler.ReduceLROnPlateau(optimizerF1, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "  criterion = nn.NLLLoss()\n",
    "\n",
    "  lossF,val_lossF=fit(modelF,device,optimizerF,schedulerF,criterion,train_loader,val_loader,Temp,epochs)\n",
    "  fig = plt.figure(figsize=(5,5))\n",
    "  plt.plot(np.arange(1,epochs+1), lossF, \"*-\",label=\"Loss\")\n",
    "  plt.plot(np.arange(1,epochs+1), val_lossF,\"o-\",label=\"Val Loss\")\n",
    "  plt.title(\"Network F\")\n",
    "  plt.xlabel(\"Num of epochs\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  #converting target labels to soft labels\n",
    "  for data in train_loader:\n",
    "    input, label  = data[0].to(device),data[1].to(device)\n",
    "    softlabel  = F.log_softmax(modelF(input),dim=1)\n",
    "    data[1] = softlabel\n",
    "\n",
    "  lossF1,val_lossF1=fit(modelF1,device,optimizerF1,schedulerF1,criterion,train_loader,val_loader,Temp,epochs)\n",
    "  fig = plt.figure(figsize=(5,5))\n",
    "  plt.plot(np.arange(1,epochs+1), lossF1, \"*-\",label=\"Loss\")\n",
    "  plt.plot(np.arange(1,epochs+1), val_lossF1,\"o-\",label=\"Val Loss\")\n",
    "  plt.title(\"Network F'\")\n",
    "  plt.xlabel(\"Num of epochs\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  model = NetF1().to(device)\n",
    "  model.load_state_dict(modelF1.state_dict())\n",
    "  for attack in (\"fgsm\",\"ifgsm\",\"mifgsm\"):\n",
    "    accuracies = []\n",
    "    examples = []\n",
    "    for eps in epsilons:\n",
    "        acc, ex = test(model,device,test_loader,eps,1,\"fgsm\")\n",
    "        accuracies.append(acc)\n",
    "        examples.append(ex)\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(epsilons, accuracies, \"*-\")\n",
    "    plt.title(attack)\n",
    "    plt.xlabel(\"Epsilon\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    cnt = 0\n",
    "    plt.figure(figsize=(8,10))\n",
    "    for i in range(len(epsilons)):\n",
    "        for j in range(len(examples[i])):\n",
    "            cnt += 1\n",
    "            plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "            plt.xticks([], [])\n",
    "            plt.yticks([], [])\n",
    "            if j == 0:\n",
    "                plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "            orig,adv,ex = examples[i][j]\n",
    "            plt.title(\"{} -> {}\".format(orig, adv))\n",
    "            plt.imshow(ex, cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SE_TL8MMgZiP",
    "outputId": "7f6d5779-c5be-46c8-84ed-70aabba99d96"
   },
   "outputs": [],
   "source": [
    "Temp=100\n",
    "epochs=10\n",
    "epsilons=[0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3]\n",
    "defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlIlXSQS3wh88lTwvpnKqX",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Adversarial Example (Attack and defense).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
